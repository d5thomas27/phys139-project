{
 "cells": [
  {
   "cell_type": "code",
   "id": "026b0697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T20:59:47.603497Z",
     "start_time": "2025-12-09T20:59:47.599329Z"
    }
   },
   "source": [
    "from keras.src.callbacks import EarlyStopping\n",
    "from yaml import unsafe_load\n",
    "\n",
    "from database_io import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "a8fdd65b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T20:59:48.032105Z",
     "start_time": "2025-12-09T20:59:48.027481Z"
    }
   },
   "source": [
    "# path of databases (must exist)\n",
    "db_path = \"db/\"\n",
    "\n",
    "# filenames of databases (this must be sqlite3 databases)\n",
    "train_fname = \"surf17_train.db\"\n",
    "validation_fname = \"surf17_validation.db\"\n",
    "test_fname = \"surf17_test.db\"\n",
    "\n",
    "dim_syndr = 8\n",
    "dim_fsyndr = 4\n",
    "n_steps_net1 = 20\n",
    "n_steps_net2 = 3\n",
    "\n",
    "data = DatabaseIO(dim_syndr, dim_fsyndr, n_steps_net1, n_steps_net2)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "bec982d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T20:59:49.504335Z",
     "start_time": "2025-12-09T20:59:48.504375Z"
    }
   },
   "source": [
    "try:\n",
    "    data.close_databases()\n",
    "except:\n",
    "    pass\n",
    "data.load_data(db_path + train_fname, db_path + validation_fname, db_path + test_fname)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "n_batches_train = 1000\n",
    "n_batches_validation = 100\n",
    "\n",
    "\n",
    "\n",
    "class DecoderSequence(Sequence):\n",
    "    def __init__(self, data, batch_size, n_batches, data_type):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.n_batches = n_batches\n",
    "        self.data_type = data_type\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # return the idx-th batch captured at epoch start\n",
    "        return self.epoch_batches[idx]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Called automatically by Keras at the end of each epoch.\"\"\"\n",
    "        gen = self.data.gen_batches(\n",
    "            self.batch_size,\n",
    "            self.n_batches,\n",
    "            data_type=self.data_type\n",
    "        )\n",
    "\n",
    "        self.epoch_batches = []\n",
    "        for _ in range(self.n_batches):\n",
    "            batch_x1, batch_x2, batch_fx, batch_l1, batch_l2, batch_y = next(gen)\n",
    "\n",
    "            # Wrap into Keras multi-input format\n",
    "            inputs = (batch_x1, batch_x2, batch_fx) # batch_l1) #, batch_l1, batch_l2)\n",
    "            outputs = batch_y\n",
    "            self.epoch_batches.append((inputs, outputs))\n",
    "\n",
    "train_seq = DecoderSequence(\n",
    "    data,\n",
    "    batch_size=batch_size,\n",
    "    n_batches=n_batches_train,\n",
    "    data_type='training'\n",
    ")\n",
    "\n",
    "val_seq = DecoderSequence(\n",
    "    data,\n",
    "    batch_size=batch_size,\n",
    "    n_batches=n_batches_validation,\n",
    "    data_type='validation'\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded databases and checked exclusiveness training, validation, and test keys\n",
      "N_training=400000, N_validaiton=10000, N_test=5000.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "id": "56560b65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T22:04:54.781112Z",
     "start_time": "2025-12-09T20:59:50.120849Z"
    }
   },
   "source": [
    "x1 = Input(shape=(None, dim_syndr), name=\"x1_full\")\n",
    "x2 = Input(shape=(n_steps_net2, dim_syndr), name=\"x2_recent\")\n",
    "fx = Input(shape=(dim_fsyndr,), name=\"final_increment\")\n",
    "\n",
    "# l1_input = Input(shape=(), dtype=tf.int32, name=\"seq_len\")\n",
    "\n",
    "x1_masked = layers.Masking(mask_value=0.0)(x1)\n",
    "\n",
    "dropout_rate = 0.2\n",
    "layer_depth = 64\n",
    "\n",
    "\n",
    "\n",
    "# mask_layer = layers.Lambda(lambda x: tf.sequence_mask(x[1], maxlen=tf.shape(x[0])[1]), output_shape=(None,))([x1, l1_input])\n",
    "\n",
    "\n",
    "# Network 1 ---> Full history without final syndrome\n",
    "h1 = layers.LSTM(layer_depth, activation=\"tanh\", return_sequences=True, kernel_regularizer=keras.regularizers.l2(1e-5))(x1_masked)\n",
    "h1 = layers.Dropout(dropout_rate)(h1)\n",
    "h1 = layers.LSTM(layer_depth, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(1e-5))(h1)\n",
    "h1 = layers.Dropout(dropout_rate)(h1)\n",
    "\n",
    "p1 = layers.Dense(layer_depth, activation=\"relu\", name=\"p1\", kernel_regularizer=keras.regularizers.l2(1e-5))(h1)\n",
    "p1 = layers.Dropout(dropout_rate)(p1)\n",
    "p1 = layers.Dense(1, activation=\"sigmoid\", kernel_regularizer=keras.regularizers.l2(1e-5), name=\"p1_prob\")(p1)\n",
    "\n",
    "\n",
    "\n",
    "# Network 2 ----> recent syndrome with final increment\n",
    "h2 = layers.LSTM(layer_depth, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(1e-5), return_sequences=True)(x2)\n",
    "h2 = layers.Dropout(dropout_rate)(h2)\n",
    "h2 = layers.LSTM(layer_depth, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(1e-5))(h2)\n",
    "h2 = layers.Dropout(dropout_rate)(h2)\n",
    "\n",
    "p2 = layers.Concatenate()([h2, fx])\n",
    "p2 = layers.Dense(layer_depth, activation=\"relu\", name=\"p2\", kernel_regularizer=keras.regularizers.l2(1e-5))(p2)\n",
    "p2 = layers.Dropout(dropout_rate)(p2)\n",
    "p2 = layers.Dense(1, activation=\"sigmoid\", name=\"p2_prob\", kernel_regularizer=keras.regularizers.l2(1e-5))(p2)\n",
    "\n",
    "\n",
    "\n",
    "# Final combination p = probabilistic sum\n",
    "# p_final = layers.Lambda(lambda x: x[0]*(1-x[1]) + x[1]*(1-x[0]))([p1, p2])\n",
    "p_final = p1*(1 - p2) + p2*(1 - p1) # XOR Gate\n",
    "\n",
    "model = Model(inputs=[x1, x2, fx], outputs=p_final)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',        # file path to save the model\n",
    "    monitor='val_accuracy',    # metric to monitor\n",
    "    verbose=1,                 # prints message when saving\n",
    "    save_best_only=True,       # only save if improved\n",
    "    mode='max'                 # 'min' for loss, 'max' for accuracy\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',    # use validation accuracy to monitor\n",
    "    patience=50,               # stop after n epochs with no improvement\n",
    "    min_delta=1e-4,            # threshold for minimum change over epochs -> \"no improvement\"\n",
    "    restore_best_weights=True, # keeps weights from the best epoch\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "results = model.fit(\n",
    "    train_seq,\n",
    "    steps_per_epoch=n_batches_train,\n",
    "    epochs=num_epochs,\n",
    "    verbose=1,\n",
    "    validation_data=val_seq,\n",
    "    validation_steps=n_batches_validation,\n",
    "    callbacks=[checkpoint, early_stop]\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_7\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ x1_full             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ x1_full[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mNotEqual\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ x2_recent           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m8\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_6 (\u001B[38;5;33mMasking\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ x1_full[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_6 (\u001B[38;5;33mAny\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ not_equal_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_30 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │     \u001B[38;5;34m18,688\u001B[0m │ x2_recent[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_28 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)  │     \u001B[38;5;34m18,688\u001B[0m │ masking_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],  │\n",
       "│                     │                   │            │ any_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_45          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │          \u001B[38;5;34m0\u001B[0m │ lstm_30[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_42          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ lstm_28[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_31 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │     \u001B[38;5;34m33,024\u001B[0m │ dropout_45[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_29 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │     \u001B[38;5;34m33,024\u001B[0m │ dropout_42[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n",
       "│                     │                   │            │ any_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_46          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ lstm_31[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_increment     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_43          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ lstm_29[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m68\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ dropout_46[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n",
       "│ (\u001B[38;5;33mConcatenate\u001B[0m)       │                   │            │ final_increment[\u001B[38;5;34m…\u001B[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1 (\u001B[38;5;33mDense\u001B[0m)          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │      \u001B[38;5;34m4,160\u001B[0m │ dropout_43[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2 (\u001B[38;5;33mDense\u001B[0m)          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │      \u001B[38;5;34m4,416\u001B[0m │ concatenate_7[\u001B[38;5;34m0\u001B[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_44          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ p1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_47          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ p2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1_prob (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m65\u001B[0m │ dropout_44[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2_prob (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m65\u001B[0m │ dropout_47[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_4          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p2_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mSubtract\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_5          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p1_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mSubtract\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_4          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p1_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n",
       "│ (\u001B[38;5;33mMultiply\u001B[0m)          │                   │            │ subtract_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_5          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p2_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n",
       "│ (\u001B[38;5;33mMultiply\u001B[0m)          │                   │            │ subtract_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001B[38;5;33mAdd\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ multiply_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n",
       "│                     │                   │            │ multiply_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ x1_full             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ x1_full[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ x2_recent           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ x1_full[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │ x2_recent[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │ masking_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ any_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_45          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_42          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dropout_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ any_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_46          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_increment     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_43          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ final_increment[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,416</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_44          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1_prob (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2_prob (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p2_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p1_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p1_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ subtract_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p2_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ subtract_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ multiply_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m112,130\u001B[0m (438.01 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,130</span> (438.01 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m112,130\u001B[0m (438.01 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,130</span> (438.01 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.6266 - loss: 0.6048\n",
      "Epoch 1: val_accuracy improved from None to 0.49906, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 17ms/step - accuracy: 0.6953 - loss: 0.5124 - val_accuracy: 0.4991 - val_loss: 0.7010\n",
      "Epoch 2/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8516 - loss: 0.3266\n",
      "Epoch 2: val_accuracy improved from 0.49906 to 0.58203, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.8719 - loss: 0.2971 - val_accuracy: 0.5820 - val_loss: 0.6681\n",
      "Epoch 3/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.8990 - loss: 0.2470\n",
      "Epoch 3: val_accuracy improved from 0.58203 to 0.59203, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9013 - loss: 0.2392 - val_accuracy: 0.5920 - val_loss: 0.6483\n",
      "Epoch 4/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9029 - loss: 0.2264\n",
      "Epoch 4: val_accuracy improved from 0.59203 to 0.59219, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9059 - loss: 0.2226 - val_accuracy: 0.5922 - val_loss: 0.6468\n",
      "Epoch 5/1000\n",
      "\u001B[1m 996/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9071 - loss: 0.2153\n",
      "Epoch 5: val_accuracy improved from 0.59219 to 0.61125, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9090 - loss: 0.2147 - val_accuracy: 0.6112 - val_loss: 0.6325\n",
      "Epoch 6/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9146 - loss: 0.2058\n",
      "Epoch 6: val_accuracy improved from 0.61125 to 0.62313, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9139 - loss: 0.2073 - val_accuracy: 0.6231 - val_loss: 0.6210\n",
      "Epoch 7/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9194 - loss: 0.1983\n",
      "Epoch 7: val_accuracy did not improve from 0.62313\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9196 - loss: 0.1965 - val_accuracy: 0.6231 - val_loss: 0.6189\n",
      "Epoch 8/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9193 - loss: 0.1940\n",
      "Epoch 8: val_accuracy improved from 0.62313 to 0.63234, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9201 - loss: 0.1956 - val_accuracy: 0.6323 - val_loss: 0.6203\n",
      "Epoch 9/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9230 - loss: 0.1879\n",
      "Epoch 9: val_accuracy improved from 0.63234 to 0.66109, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9237 - loss: 0.1881 - val_accuracy: 0.6611 - val_loss: 0.6589\n",
      "Epoch 10/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 121ms/step - accuracy: 0.9264 - loss: 0.1860\n",
      "Epoch 10: val_accuracy improved from 0.66109 to 0.66766, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m123s\u001B[0m 123ms/step - accuracy: 0.9270 - loss: 0.1850 - val_accuracy: 0.6677 - val_loss: 0.5802\n",
      "Epoch 11/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9257 - loss: 0.1863\n",
      "Epoch 11: val_accuracy did not improve from 0.66766\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9264 - loss: 0.1854 - val_accuracy: 0.6594 - val_loss: 0.5857\n",
      "Epoch 12/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9318 - loss: 0.1789\n",
      "Epoch 12: val_accuracy did not improve from 0.66766\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9315 - loss: 0.1775 - val_accuracy: 0.6361 - val_loss: 0.6036\n",
      "Epoch 13/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9305 - loss: 0.1761\n",
      "Epoch 13: val_accuracy did not improve from 0.66766\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9303 - loss: 0.1780 - val_accuracy: 0.6619 - val_loss: 0.5829\n",
      "Epoch 14/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9324 - loss: 0.1754\n",
      "Epoch 14: val_accuracy did not improve from 0.66766\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9315 - loss: 0.1764 - val_accuracy: 0.6661 - val_loss: 0.5909\n",
      "Epoch 15/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9318 - loss: 0.1778\n",
      "Epoch 15: val_accuracy did not improve from 0.66766\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9334 - loss: 0.1757 - val_accuracy: 0.6667 - val_loss: 0.5877\n",
      "Epoch 16/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9335 - loss: 0.1747\n",
      "Epoch 16: val_accuracy improved from 0.66766 to 0.67422, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9348 - loss: 0.1736 - val_accuracy: 0.6742 - val_loss: 0.5918\n",
      "Epoch 17/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9328 - loss: 0.1738\n",
      "Epoch 17: val_accuracy improved from 0.67422 to 0.68281, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9348 - loss: 0.1721 - val_accuracy: 0.6828 - val_loss: 0.5845\n",
      "Epoch 18/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9385 - loss: 0.1694\n",
      "Epoch 18: val_accuracy did not improve from 0.68281\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 15ms/step - accuracy: 0.9388 - loss: 0.1662 - val_accuracy: 0.6825 - val_loss: 0.5714\n",
      "Epoch 19/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 69ms/step - accuracy: 0.9375 - loss: 0.1682\n",
      "Epoch 19: val_accuracy improved from 0.68281 to 0.69047, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m71s\u001B[0m 71ms/step - accuracy: 0.9379 - loss: 0.1671 - val_accuracy: 0.6905 - val_loss: 0.5851\n",
      "Epoch 20/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9411 - loss: 0.1621\n",
      "Epoch 20: val_accuracy did not improve from 0.69047\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9404 - loss: 0.1642 - val_accuracy: 0.6878 - val_loss: 0.5770\n",
      "Epoch 21/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9409 - loss: 0.1621\n",
      "Epoch 21: val_accuracy did not improve from 0.69047\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9418 - loss: 0.1628 - val_accuracy: 0.6773 - val_loss: 0.5710\n",
      "Epoch 22/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9437 - loss: 0.1598\n",
      "Epoch 22: val_accuracy did not improve from 0.69047\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9434 - loss: 0.1610 - val_accuracy: 0.6684 - val_loss: 0.5814\n",
      "Epoch 23/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9422 - loss: 0.1636\n",
      "Epoch 23: val_accuracy did not improve from 0.69047\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9419 - loss: 0.1646 - val_accuracy: 0.6873 - val_loss: 0.5655\n",
      "Epoch 24/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9417 - loss: 0.1623\n",
      "Epoch 24: val_accuracy did not improve from 0.69047\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9427 - loss: 0.1601 - val_accuracy: 0.6727 - val_loss: 0.5718\n",
      "Epoch 25/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9445 - loss: 0.1581\n",
      "Epoch 25: val_accuracy improved from 0.69047 to 0.69500, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9439 - loss: 0.1576 - val_accuracy: 0.6950 - val_loss: 0.5708\n",
      "Epoch 26/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9439 - loss: 0.1576\n",
      "Epoch 26: val_accuracy improved from 0.69500 to 0.70438, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9433 - loss: 0.1590 - val_accuracy: 0.7044 - val_loss: 0.5695\n",
      "Epoch 27/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9444 - loss: 0.1577\n",
      "Epoch 27: val_accuracy did not improve from 0.70438\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9448 - loss: 0.1564 - val_accuracy: 0.6939 - val_loss: 0.5718\n",
      "Epoch 28/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9442 - loss: 0.1559\n",
      "Epoch 28: val_accuracy did not improve from 0.70438\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9453 - loss: 0.1558 - val_accuracy: 0.6911 - val_loss: 0.5609\n",
      "Epoch 29/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9447 - loss: 0.1560\n",
      "Epoch 29: val_accuracy did not improve from 0.70438\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9454 - loss: 0.1550 - val_accuracy: 0.6909 - val_loss: 0.5752\n",
      "Epoch 30/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9456 - loss: 0.1534\n",
      "Epoch 30: val_accuracy improved from 0.70438 to 0.70688, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9458 - loss: 0.1548 - val_accuracy: 0.7069 - val_loss: 0.6278\n",
      "Epoch 31/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9464 - loss: 0.1525\n",
      "Epoch 31: val_accuracy did not improve from 0.70688\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9454 - loss: 0.1549 - val_accuracy: 0.6978 - val_loss: 0.5602\n",
      "Epoch 32/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9457 - loss: 0.1532\n",
      "Epoch 32: val_accuracy did not improve from 0.70688\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9466 - loss: 0.1518 - val_accuracy: 0.7041 - val_loss: 0.5850\n",
      "Epoch 33/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9461 - loss: 0.1551\n",
      "Epoch 33: val_accuracy did not improve from 0.70688\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9465 - loss: 0.1531 - val_accuracy: 0.6408 - val_loss: 0.5859\n",
      "Epoch 34/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9466 - loss: 0.1547\n",
      "Epoch 34: val_accuracy did not improve from 0.70688\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m589s\u001B[0m 590ms/step - accuracy: 0.9462 - loss: 0.1543 - val_accuracy: 0.6830 - val_loss: 0.5613\n",
      "Epoch 35/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - accuracy: 0.9493 - loss: 0.1456\n",
      "Epoch 35: val_accuracy did not improve from 0.70688\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 23ms/step - accuracy: 0.9490 - loss: 0.1479 - val_accuracy: 0.6898 - val_loss: 0.5652\n",
      "Epoch 36/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 76ms/step - accuracy: 0.9460 - loss: 0.1551\n",
      "Epoch 36: val_accuracy did not improve from 0.70688\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m80s\u001B[0m 80ms/step - accuracy: 0.9467 - loss: 0.1540 - val_accuracy: 0.6919 - val_loss: 0.5553\n",
      "Epoch 37/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 398ms/step - accuracy: 0.9483 - loss: 0.1482\n",
      "Epoch 37: val_accuracy improved from 0.70688 to 0.72203, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m400s\u001B[0m 400ms/step - accuracy: 0.9482 - loss: 0.1492 - val_accuracy: 0.7220 - val_loss: 0.5726\n",
      "Epoch 38/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9487 - loss: 0.1478\n",
      "Epoch 38: val_accuracy did not improve from 0.72203\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 15ms/step - accuracy: 0.9476 - loss: 0.1521 - val_accuracy: 0.7178 - val_loss: 0.5811\n",
      "Epoch 39/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9467 - loss: 0.1517\n",
      "Epoch 39: val_accuracy did not improve from 0.72203\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9476 - loss: 0.1497 - val_accuracy: 0.7086 - val_loss: 0.5475\n",
      "Epoch 40/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9465 - loss: 0.1532\n",
      "Epoch 40: val_accuracy did not improve from 0.72203\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9471 - loss: 0.1519 - val_accuracy: 0.6389 - val_loss: 0.6018\n",
      "Epoch 41/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9487 - loss: 0.1499\n",
      "Epoch 41: val_accuracy did not improve from 0.72203\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9492 - loss: 0.1478 - val_accuracy: 0.7020 - val_loss: 0.5615\n",
      "Epoch 42/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9476 - loss: 0.1488\n",
      "Epoch 42: val_accuracy did not improve from 0.72203\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9473 - loss: 0.1499 - val_accuracy: 0.6947 - val_loss: 0.5538\n",
      "Epoch 43/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9486 - loss: 0.1481\n",
      "Epoch 43: val_accuracy did not improve from 0.72203\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9482 - loss: 0.1464 - val_accuracy: 0.6923 - val_loss: 0.5555\n",
      "Epoch 44/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9499 - loss: 0.1474\n",
      "Epoch 44: val_accuracy did not improve from 0.72203\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9499 - loss: 0.1470 - val_accuracy: 0.7083 - val_loss: 0.5739\n",
      "Epoch 45/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9502 - loss: 0.1447\n",
      "Epoch 45: val_accuracy did not improve from 0.72203\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9488 - loss: 0.1481 - val_accuracy: 0.7195 - val_loss: 0.5770\n",
      "Epoch 46/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9484 - loss: 0.1461\n",
      "Epoch 46: val_accuracy did not improve from 0.72203\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9490 - loss: 0.1462 - val_accuracy: 0.7159 - val_loss: 0.5380\n",
      "Epoch 47/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9508 - loss: 0.1461\n",
      "Epoch 47: val_accuracy did not improve from 0.72203\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m629s\u001B[0m 630ms/step - accuracy: 0.9505 - loss: 0.1445 - val_accuracy: 0.7095 - val_loss: 0.5841\n",
      "Epoch 48/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9494 - loss: 0.1473\n",
      "Epoch 48: val_accuracy improved from 0.72203 to 0.73406, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9494 - loss: 0.1449 - val_accuracy: 0.7341 - val_loss: 0.5458\n",
      "Epoch 49/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9498 - loss: 0.1466\n",
      "Epoch 49: val_accuracy did not improve from 0.73406\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9503 - loss: 0.1454 - val_accuracy: 0.7105 - val_loss: 0.5473\n",
      "Epoch 50/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.9502 - loss: 0.1475\n",
      "Epoch 50: val_accuracy did not improve from 0.73406\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 15ms/step - accuracy: 0.9505 - loss: 0.1455 - val_accuracy: 0.7273 - val_loss: 0.5563\n",
      "Epoch 51/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9474 - loss: 0.1479\n",
      "Epoch 51: val_accuracy did not improve from 0.73406\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9494 - loss: 0.1455 - val_accuracy: 0.7134 - val_loss: 0.5643\n",
      "Epoch 52/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9505 - loss: 0.1440\n",
      "Epoch 52: val_accuracy improved from 0.73406 to 0.73484, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9506 - loss: 0.1434 - val_accuracy: 0.7348 - val_loss: 0.5534\n",
      "Epoch 53/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9506 - loss: 0.1438\n",
      "Epoch 53: val_accuracy did not improve from 0.73484\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9496 - loss: 0.1453 - val_accuracy: 0.7237 - val_loss: 0.5407\n",
      "Epoch 54/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9517 - loss: 0.1418\n",
      "Epoch 54: val_accuracy did not improve from 0.73484\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9507 - loss: 0.1428 - val_accuracy: 0.7275 - val_loss: 0.5627\n",
      "Epoch 55/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9531 - loss: 0.1390\n",
      "Epoch 55: val_accuracy did not improve from 0.73484\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9513 - loss: 0.1426 - val_accuracy: 0.7291 - val_loss: 0.5536\n",
      "Epoch 56/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9506 - loss: 0.1435\n",
      "Epoch 56: val_accuracy did not improve from 0.73484\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9507 - loss: 0.1426 - val_accuracy: 0.7328 - val_loss: 0.5807\n",
      "Epoch 57/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9513 - loss: 0.1459\n",
      "Epoch 57: val_accuracy did not improve from 0.73484\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9516 - loss: 0.1435 - val_accuracy: 0.7233 - val_loss: 0.5868\n",
      "Epoch 58/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9497 - loss: 0.1467\n",
      "Epoch 58: val_accuracy did not improve from 0.73484\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9507 - loss: 0.1421 - val_accuracy: 0.7178 - val_loss: 0.5869\n",
      "Epoch 59/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9518 - loss: 0.1409\n",
      "Epoch 59: val_accuracy improved from 0.73484 to 0.73734, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9507 - loss: 0.1435 - val_accuracy: 0.7373 - val_loss: 0.5525\n",
      "Epoch 60/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9538 - loss: 0.1379\n",
      "Epoch 60: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9522 - loss: 0.1408 - val_accuracy: 0.7303 - val_loss: 0.6361\n",
      "Epoch 61/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9519 - loss: 0.1384\n",
      "Epoch 61: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9518 - loss: 0.1404 - val_accuracy: 0.7336 - val_loss: 0.6291\n",
      "Epoch 62/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9520 - loss: 0.1383\n",
      "Epoch 62: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9516 - loss: 0.1404 - val_accuracy: 0.7230 - val_loss: 0.6453\n",
      "Epoch 63/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9519 - loss: 0.1407\n",
      "Epoch 63: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9516 - loss: 0.1414 - val_accuracy: 0.7059 - val_loss: 0.5841\n",
      "Epoch 64/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9517 - loss: 0.1413\n",
      "Epoch 64: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9526 - loss: 0.1394 - val_accuracy: 0.7348 - val_loss: 0.6356\n",
      "Epoch 65/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9509 - loss: 0.1426\n",
      "Epoch 65: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9507 - loss: 0.1447 - val_accuracy: 0.7088 - val_loss: 0.5788\n",
      "Epoch 66/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - accuracy: 0.9501 - loss: 0.1445\n",
      "Epoch 66: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 24ms/step - accuracy: 0.9501 - loss: 0.1451 - val_accuracy: 0.7252 - val_loss: 0.5988\n",
      "Epoch 67/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9513 - loss: 0.1426\n",
      "Epoch 67: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9517 - loss: 0.1408 - val_accuracy: 0.7234 - val_loss: 0.5992\n",
      "Epoch 68/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9518 - loss: 0.1413\n",
      "Epoch 68: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9522 - loss: 0.1397 - val_accuracy: 0.7266 - val_loss: 0.6851\n",
      "Epoch 69/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9519 - loss: 0.1439\n",
      "Epoch 69: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9510 - loss: 0.1430 - val_accuracy: 0.7258 - val_loss: 0.5885\n",
      "Epoch 70/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9528 - loss: 0.1409\n",
      "Epoch 70: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9533 - loss: 0.1394 - val_accuracy: 0.7362 - val_loss: 0.5898\n",
      "Epoch 71/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9496 - loss: 0.1432\n",
      "Epoch 71: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9511 - loss: 0.1423 - val_accuracy: 0.7300 - val_loss: 0.6177\n",
      "Epoch 72/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9546 - loss: 0.1347\n",
      "Epoch 72: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9526 - loss: 0.1374 - val_accuracy: 0.7289 - val_loss: 0.6173\n",
      "Epoch 73/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9528 - loss: 0.1369\n",
      "Epoch 73: val_accuracy did not improve from 0.73734\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9514 - loss: 0.1394 - val_accuracy: 0.7320 - val_loss: 0.6144\n",
      "Epoch 74/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9516 - loss: 0.1403\n",
      "Epoch 74: val_accuracy improved from 0.73734 to 0.73922, saving model to best_model.keras\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9529 - loss: 0.1385 - val_accuracy: 0.7392 - val_loss: 0.6407\n",
      "Epoch 75/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9517 - loss: 0.1377\n",
      "Epoch 75: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9509 - loss: 0.1394 - val_accuracy: 0.7109 - val_loss: 0.5779\n",
      "Epoch 76/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9530 - loss: 0.1391\n",
      "Epoch 76: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9528 - loss: 0.1390 - val_accuracy: 0.7291 - val_loss: 0.6520\n",
      "Epoch 77/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9534 - loss: 0.1337\n",
      "Epoch 77: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9527 - loss: 0.1368 - val_accuracy: 0.7331 - val_loss: 0.6329\n",
      "Epoch 78/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9535 - loss: 0.1373\n",
      "Epoch 78: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9528 - loss: 0.1393 - val_accuracy: 0.7303 - val_loss: 0.6279\n",
      "Epoch 79/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9527 - loss: 0.1390\n",
      "Epoch 79: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9520 - loss: 0.1394 - val_accuracy: 0.7248 - val_loss: 0.5969\n",
      "Epoch 80/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9534 - loss: 0.1348\n",
      "Epoch 80: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9538 - loss: 0.1353 - val_accuracy: 0.6945 - val_loss: 0.5633\n",
      "Epoch 81/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9515 - loss: 0.1435\n",
      "Epoch 81: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9523 - loss: 0.1409 - val_accuracy: 0.7228 - val_loss: 0.5571\n",
      "Epoch 82/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9514 - loss: 0.1407\n",
      "Epoch 82: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9514 - loss: 0.1395 - val_accuracy: 0.7334 - val_loss: 0.6155\n",
      "Epoch 83/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9529 - loss: 0.1364\n",
      "Epoch 83: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9527 - loss: 0.1378 - val_accuracy: 0.7312 - val_loss: 0.6329\n",
      "Epoch 84/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9532 - loss: 0.1368\n",
      "Epoch 84: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9533 - loss: 0.1356 - val_accuracy: 0.7327 - val_loss: 0.6911\n",
      "Epoch 85/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9508 - loss: 0.1400\n",
      "Epoch 85: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9518 - loss: 0.1371 - val_accuracy: 0.7184 - val_loss: 0.5766\n",
      "Epoch 86/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9532 - loss: 0.1356\n",
      "Epoch 86: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9527 - loss: 0.1378 - val_accuracy: 0.7347 - val_loss: 0.6145\n",
      "Epoch 87/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9528 - loss: 0.1355\n",
      "Epoch 87: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9528 - loss: 0.1358 - val_accuracy: 0.7283 - val_loss: 0.6052\n",
      "Epoch 88/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9547 - loss: 0.1354\n",
      "Epoch 88: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9533 - loss: 0.1373 - val_accuracy: 0.7216 - val_loss: 0.5912\n",
      "Epoch 89/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9523 - loss: 0.1381\n",
      "Epoch 89: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9524 - loss: 0.1387 - val_accuracy: 0.7209 - val_loss: 0.5908\n",
      "Epoch 90/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9533 - loss: 0.1356\n",
      "Epoch 90: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9529 - loss: 0.1368 - val_accuracy: 0.7255 - val_loss: 0.6192\n",
      "Epoch 91/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9540 - loss: 0.1344\n",
      "Epoch 91: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9534 - loss: 0.1359 - val_accuracy: 0.7308 - val_loss: 0.6423\n",
      "Epoch 92/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9526 - loss: 0.1371\n",
      "Epoch 92: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9525 - loss: 0.1381 - val_accuracy: 0.7217 - val_loss: 0.5736\n",
      "Epoch 93/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9535 - loss: 0.1366\n",
      "Epoch 93: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9526 - loss: 0.1378 - val_accuracy: 0.7291 - val_loss: 0.6797\n",
      "Epoch 94/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9543 - loss: 0.1367\n",
      "Epoch 94: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9541 - loss: 0.1368 - val_accuracy: 0.7152 - val_loss: 0.5720\n",
      "Epoch 95/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9532 - loss: 0.1389\n",
      "Epoch 95: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9539 - loss: 0.1367 - val_accuracy: 0.7362 - val_loss: 0.6257\n",
      "Epoch 96/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9519 - loss: 0.1384\n",
      "Epoch 96: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9523 - loss: 0.1378 - val_accuracy: 0.7247 - val_loss: 0.5587\n",
      "Epoch 97/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9531 - loss: 0.1355\n",
      "Epoch 97: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9532 - loss: 0.1364 - val_accuracy: 0.7277 - val_loss: 0.5890\n",
      "Epoch 98/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9542 - loss: 0.1361\n",
      "Epoch 98: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9534 - loss: 0.1392 - val_accuracy: 0.7200 - val_loss: 0.5858\n",
      "Epoch 99/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9529 - loss: 0.1356\n",
      "Epoch 99: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9542 - loss: 0.1338 - val_accuracy: 0.7330 - val_loss: 0.5795\n",
      "Epoch 100/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9530 - loss: 0.1371\n",
      "Epoch 100: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9526 - loss: 0.1385 - val_accuracy: 0.7237 - val_loss: 0.6193\n",
      "Epoch 101/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9534 - loss: 0.1380\n",
      "Epoch 101: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9541 - loss: 0.1362 - val_accuracy: 0.7256 - val_loss: 0.5706\n",
      "Epoch 102/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9531 - loss: 0.1377\n",
      "Epoch 102: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9535 - loss: 0.1374 - val_accuracy: 0.7109 - val_loss: 0.5533\n",
      "Epoch 103/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9541 - loss: 0.1387\n",
      "Epoch 103: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9537 - loss: 0.1377 - val_accuracy: 0.7386 - val_loss: 0.6008\n",
      "Epoch 104/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9549 - loss: 0.1336\n",
      "Epoch 104: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9543 - loss: 0.1352 - val_accuracy: 0.7261 - val_loss: 0.6456\n",
      "Epoch 105/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9536 - loss: 0.1372\n",
      "Epoch 105: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9536 - loss: 0.1365 - val_accuracy: 0.7309 - val_loss: 0.6676\n",
      "Epoch 106/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9563 - loss: 0.1294\n",
      "Epoch 106: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9548 - loss: 0.1320 - val_accuracy: 0.7241 - val_loss: 0.6018\n",
      "Epoch 107/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9534 - loss: 0.1338\n",
      "Epoch 107: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9535 - loss: 0.1343 - val_accuracy: 0.7337 - val_loss: 0.5922\n",
      "Epoch 108/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9554 - loss: 0.1335\n",
      "Epoch 108: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9544 - loss: 0.1354 - val_accuracy: 0.7197 - val_loss: 0.5713\n",
      "Epoch 109/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9528 - loss: 0.1391\n",
      "Epoch 109: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9521 - loss: 0.1398 - val_accuracy: 0.7239 - val_loss: 0.5743\n",
      "Epoch 110/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9549 - loss: 0.1360\n",
      "Epoch 110: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9551 - loss: 0.1350 - val_accuracy: 0.7211 - val_loss: 0.5790\n",
      "Epoch 111/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9542 - loss: 0.1338\n",
      "Epoch 111: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9543 - loss: 0.1345 - val_accuracy: 0.7028 - val_loss: 0.5781\n",
      "Epoch 112/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9537 - loss: 0.1362\n",
      "Epoch 112: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9539 - loss: 0.1368 - val_accuracy: 0.7347 - val_loss: 0.6178\n",
      "Epoch 113/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9547 - loss: 0.1345\n",
      "Epoch 113: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 18ms/step - accuracy: 0.9549 - loss: 0.1342 - val_accuracy: 0.7231 - val_loss: 0.6373\n",
      "Epoch 114/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9544 - loss: 0.1346\n",
      "Epoch 114: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9543 - loss: 0.1353 - val_accuracy: 0.7250 - val_loss: 0.6195\n",
      "Epoch 115/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 15ms/step - accuracy: 0.9561 - loss: 0.1324\n",
      "Epoch 115: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 18ms/step - accuracy: 0.9560 - loss: 0.1319 - val_accuracy: 0.7008 - val_loss: 0.5774\n",
      "Epoch 116/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 67ms/step - accuracy: 0.9574 - loss: 0.1308\n",
      "Epoch 116: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m69s\u001B[0m 69ms/step - accuracy: 0.9567 - loss: 0.1309 - val_accuracy: 0.7380 - val_loss: 0.6284\n",
      "Epoch 117/1000\n",
      "\u001B[1m 998/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9529 - loss: 0.1361\n",
      "Epoch 117: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9537 - loss: 0.1354 - val_accuracy: 0.7228 - val_loss: 0.5892\n",
      "Epoch 118/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9550 - loss: 0.1333\n",
      "Epoch 118: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9548 - loss: 0.1321 - val_accuracy: 0.7294 - val_loss: 0.6594\n",
      "Epoch 119/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 13ms/step - accuracy: 0.9558 - loss: 0.1329\n",
      "Epoch 119: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9552 - loss: 0.1347 - val_accuracy: 0.7258 - val_loss: 0.5906\n",
      "Epoch 120/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9523 - loss: 0.1357\n",
      "Epoch 120: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9539 - loss: 0.1341 - val_accuracy: 0.7280 - val_loss: 0.5481\n",
      "Epoch 121/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9533 - loss: 0.1358\n",
      "Epoch 121: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 16ms/step - accuracy: 0.9545 - loss: 0.1341 - val_accuracy: 0.7169 - val_loss: 0.6063\n",
      "Epoch 122/1000\n",
      "\u001B[1m 997/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9563 - loss: 0.1304\n",
      "Epoch 122: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9555 - loss: 0.1322 - val_accuracy: 0.7150 - val_loss: 0.5800\n",
      "Epoch 123/1000\n",
      "\u001B[1m 999/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 14ms/step - accuracy: 0.9544 - loss: 0.1364\n",
      "Epoch 123: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 17ms/step - accuracy: 0.9546 - loss: 0.1369 - val_accuracy: 0.7217 - val_loss: 0.6428\n",
      "Epoch 124/1000\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - accuracy: 0.9565 - loss: 0.1313\n",
      "Epoch 124: val_accuracy did not improve from 0.73922\n",
      "\u001B[1m1000/1000\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 19ms/step - accuracy: 0.9557 - loss: 0.1314 - val_accuracy: 0.7270 - val_loss: 0.6029\n",
      "Epoch 124: early stopping\n",
      "Restoring model weights from the end of the best epoch: 74.\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T23:11:37.673130Z",
     "start_time": "2025-12-09T23:11:37.647387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Model inputs:\", model.inputs)\n",
    "print(\"Model outputs:\", model.outputs)\n",
    "model.summary()"
   ],
   "id": "d05a2acb001dd257",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model inputs: [<KerasTensor shape=(None, None, 8), dtype=float32, sparse=False, ragged=False, name=x1_full>, <KerasTensor shape=(None, 3, 8), dtype=float32, sparse=False, ragged=False, name=x2_recent>, <KerasTensor shape=(None, 4), dtype=float32, sparse=False, ragged=False, name=final_increment>]\n",
      "Model outputs: [<KerasTensor shape=(None, 1), dtype=float32, sparse=False, ragged=False, name=keras_tensor_204>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_7\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ x1_full             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ x1_full[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mNotEqual\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ x2_recent           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m8\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_6 (\u001B[38;5;33mMasking\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ x1_full[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_6 (\u001B[38;5;33mAny\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ not_equal_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_30 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │     \u001B[38;5;34m18,688\u001B[0m │ x2_recent[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_28 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)  │     \u001B[38;5;34m18,688\u001B[0m │ masking_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],  │\n",
       "│                     │                   │            │ any_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_45          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │          \u001B[38;5;34m0\u001B[0m │ lstm_30[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_42          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ lstm_28[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_31 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │     \u001B[38;5;34m33,024\u001B[0m │ dropout_45[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_29 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │     \u001B[38;5;34m33,024\u001B[0m │ dropout_42[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n",
       "│                     │                   │            │ any_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_46          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ lstm_31[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_increment     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_43          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ lstm_29[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m68\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ dropout_46[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n",
       "│ (\u001B[38;5;33mConcatenate\u001B[0m)       │                   │            │ final_increment[\u001B[38;5;34m…\u001B[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1 (\u001B[38;5;33mDense\u001B[0m)          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │      \u001B[38;5;34m4,160\u001B[0m │ dropout_43[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2 (\u001B[38;5;33mDense\u001B[0m)          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │      \u001B[38;5;34m4,416\u001B[0m │ concatenate_7[\u001B[38;5;34m0\u001B[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_44          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ p1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_47          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ p2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1_prob (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m65\u001B[0m │ dropout_44[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2_prob (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m65\u001B[0m │ dropout_47[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_4          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p2_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mSubtract\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_5          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p1_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mSubtract\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_4          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p1_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n",
       "│ (\u001B[38;5;33mMultiply\u001B[0m)          │                   │            │ subtract_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_5          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p2_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n",
       "│ (\u001B[38;5;33mMultiply\u001B[0m)          │                   │            │ subtract_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001B[38;5;33mAdd\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ multiply_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n",
       "│                     │                   │            │ multiply_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ x1_full             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ x1_full[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ x2_recent           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ x1_full[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │ x2_recent[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │ masking_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ any_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_45          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_42          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dropout_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ any_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_46          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_increment     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_43          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ final_increment[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,416</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_44          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1_prob (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2_prob (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p2_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p1_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p1_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ subtract_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p2_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ subtract_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ multiply_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m336,392\u001B[0m (1.28 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">336,392</span> (1.28 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m112,130\u001B[0m (438.01 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,130</span> (438.01 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m224,262\u001B[0m (876.03 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,262</span> (876.03 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T23:11:39.069068Z",
     "start_time": "2025-12-09T23:11:38.749582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = keras.models.load_model(\"best_model.keras\", safe_mode=False)\n",
    "\n",
    "print(\"Model inputs:\", model.inputs)\n",
    "print(\"Model outputs:\", model.outputs)\n",
    "model.summary()\n",
    "\n"
   ],
   "id": "eb9058feb0d2ce52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model inputs: [<KerasTensor shape=(None, None, 8), dtype=float32, sparse=False, ragged=False, name=x1_full>, <KerasTensor shape=(None, 3, 8), dtype=float32, sparse=False, ragged=False, name=x2_recent>, <KerasTensor shape=(None, 4), dtype=float32, sparse=False, ragged=False, name=final_increment>]\n",
      "Model outputs: [<KerasTensor shape=(None, 1), dtype=float32, sparse=False, ragged=False, name=keras_tensor_266>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_7\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ x1_full             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ x1_full[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mNotEqual\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ x2_recent           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m8\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_6 (\u001B[38;5;33mMasking\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ x1_full[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_6 (\u001B[38;5;33mAny\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ not_equal_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_30 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │     \u001B[38;5;34m18,688\u001B[0m │ x2_recent[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_28 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)  │     \u001B[38;5;34m18,688\u001B[0m │ masking_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],  │\n",
       "│                     │                   │            │ any_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_45          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │          \u001B[38;5;34m0\u001B[0m │ lstm_30[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_42          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ lstm_28[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_31 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │     \u001B[38;5;34m33,024\u001B[0m │ dropout_45[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_29 (\u001B[38;5;33mLSTM\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │     \u001B[38;5;34m33,024\u001B[0m │ dropout_42[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n",
       "│                     │                   │            │ any_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_46          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ lstm_31[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_increment     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_43          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ lstm_29[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m68\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ dropout_46[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n",
       "│ (\u001B[38;5;33mConcatenate\u001B[0m)       │                   │            │ final_increment[\u001B[38;5;34m…\u001B[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1 (\u001B[38;5;33mDense\u001B[0m)          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │      \u001B[38;5;34m4,160\u001B[0m │ dropout_43[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2 (\u001B[38;5;33mDense\u001B[0m)          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │      \u001B[38;5;34m4,416\u001B[0m │ concatenate_7[\u001B[38;5;34m0\u001B[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_44          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ p1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_47          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ p2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1_prob (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m65\u001B[0m │ dropout_44[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2_prob (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │         \u001B[38;5;34m65\u001B[0m │ dropout_47[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_4          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p2_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mSubtract\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_5          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p1_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mSubtract\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_4          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p1_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n",
       "│ (\u001B[38;5;33mMultiply\u001B[0m)          │                   │            │ subtract_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_5          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ p2_prob[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n",
       "│ (\u001B[38;5;33mMultiply\u001B[0m)          │                   │            │ subtract_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001B[38;5;33mAdd\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ multiply_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m], │\n",
       "│                     │                   │            │ multiply_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ x1_full             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_6         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ x1_full[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ x2_recent           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ masking_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ x1_full[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ any_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │ x2_recent[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,688</span> │ masking_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ any_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_45          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_30[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_42          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dropout_45[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dropout_42[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ any_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_46          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_increment     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_43          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">68</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_46[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ final_increment[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dropout_43[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,416</span> │ concatenate_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_44          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_47          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p1_prob (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_44[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ p2_prob (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_47[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p2_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p1_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_4          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p1_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ subtract_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multiply_5          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ p2_prob[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          │                   │            │ subtract_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multiply_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ multiply_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m336,392\u001B[0m (1.28 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">336,392</span> (1.28 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m112,130\u001B[0m (438.01 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">112,130</span> (438.01 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m224,262\u001B[0m (876.03 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">224,262</span> (876.03 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "3dab553c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T23:11:51.729356Z",
     "start_time": "2025-12-09T23:11:51.605006Z"
    }
   },
   "source": [
    "from scipy import optimize as optim\n",
    "\n",
    "def decay(x, p_logical, x0):\n",
    "  \"\"\" This functions is used to make a exponential fit to the fidelity\n",
    "      curves \"\"\"\n",
    "  return (1 + (1 - 2 * p_logical)**(x - x0)) / 2.\n",
    "\n",
    "def calc_stats(data, n_sampling=5000, x0_max=10, verbose=False):\n",
    "    \"\"\" calculates the logical error rate and error bars \"\"\"\n",
    "\n",
    "    # since it is possible that the batch does not contain fidelities\n",
    "    # for all steps, hence we need a list with all steps for which\n",
    "    # predictions exist (we call it 'steps')\n",
    "    steps, data_nonzero = [], []\n",
    "    fids, rs_means_l, plogs_bs = [], [], []\n",
    "\n",
    "    # in the following we assume that the first step is s = 1\n",
    "    for s in range(1, len(data) + 1):\n",
    "        dat = data[s - 1]\n",
    "        if len(dat) != 0:\n",
    "            # non-trivial data points\n",
    "            steps.append(s)\n",
    "            data_nonzero.append(dat)\n",
    "            # fidelities\n",
    "            fids.append(np.mean(dat))\n",
    "\n",
    "    # fit decay curve to the non-trivial data\n",
    "    popt, pcov = optim.curve_fit(\n",
    "        decay, steps, fids, bounds=((0.0001, 0.0001), (.1, x0_max)))\n",
    "    plog, x0 = popt[0], popt[1]\n",
    "    if x0 > 0.99 * x0_max:\n",
    "        print(\"WARNING, x0 is larger than\", x0_max,\n",
    "            \"the fitting algorithm fails\")\n",
    "    if plog > .09:\n",
    "        print(\"WARNING, plog is larger than 9%, the fitting algorithm fails\")\n",
    "\n",
    "    \n",
    "\n",
    "    res_dict = {'steps': steps, 'fids': fids, 'plog': plog, 'x0': x0}\n",
    "    if verbose:\n",
    "        print(\"logical error rate:\", round(plog * 100, 5), \"%\")\n",
    "        print(\"x0 offset\", round(x0, 3))\n",
    "\n",
    "    return res_dict\n",
    "\n",
    "\n",
    "num_samples = 5000\n",
    "for batch in data.gen_batches(num_samples, 1, data_type='validation'):\n",
    "    errors = 0\n",
    "    x1, x2, fx, l1, _, y_actual = batch\n",
    "    y_pred_bool = np.empty_like(y_actual)\n",
    "    y_prob = model.predict((x1,x2,fx,l1))\n",
    "    for idx in range(y_actual.size):\n",
    "        y_pred = y_prob[idx] > 0.5\n",
    "        y_pred_bool[idx] = y_pred\n",
    "        # print(f\"Predicted Probability: {y_prob[idx]}  Prediction: {y_pred}  Actual: {y_actual[idx]}\")\n",
    "        if (y_pred != y_actual[idx]) :\n",
    "            errors += 1\n",
    "\n",
    "    comp_list = np.equal(y_pred_bool, y_actual).astype('float')\n",
    "    # reshape into a list of lists\n",
    "    comparison = []\n",
    "    for n in range(max(l1)):\n",
    "        comparison.append([])\n",
    "    for n in range(len(comp_list)):\n",
    "        idx = l1[n] - 1\n",
    "        comparison[idx].append(comp_list[n])\n",
    "    stats_dict = calc_stats(comparison, n_sampling=5000, x0_max=10, verbose=True)\n",
    "\n",
    "print(f\"Logical Fidelity: {1 - errors / num_samples}\")"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer \"functional_7\" expects 3 input(s), but it received 4 input tensors. Inputs received: [<tf.Tensor 'data:0' shape=(32, 100, 8) dtype=bool>, <tf.Tensor 'data_1:0' shape=(32, 3, 8) dtype=bool>, <tf.Tensor 'data_2:0' shape=(32, 4) dtype=bool>, <tf.Tensor 'data_3:0' shape=(32,) dtype=int32>]",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[28]\u001B[39m\u001B[32m, line 52\u001B[39m\n\u001B[32m     50\u001B[39m x1, x2, fx, l1, _, y_actual = batch\n\u001B[32m     51\u001B[39m y_pred_bool = np.empty_like(y_actual)\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m y_prob = \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx1\u001B[49m\u001B[43m,\u001B[49m\u001B[43mx2\u001B[49m\u001B[43m,\u001B[49m\u001B[43mfx\u001B[49m\u001B[43m,\u001B[49m\u001B[43ml1\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(y_actual.size):\n\u001B[32m     54\u001B[39m     y_pred = y_prob[idx] > \u001B[32m0.5\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/phys139-project/lib/python3.13/site-packages/keras/src/utils/traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/phys139-project/lib/python3.13/site-packages/keras/src/layers/input_spec.py:160\u001B[39m, in \u001B[36massert_input_compatibility\u001B[39m\u001B[34m(input_spec, inputs, layer_name)\u001B[39m\n\u001B[32m    158\u001B[39m inputs = tree.flatten(inputs)\n\u001B[32m    159\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(inputs) != \u001B[38;5;28mlen\u001B[39m(input_spec):\n\u001B[32m--> \u001B[39m\u001B[32m160\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    161\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mLayer \u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\u001B[33m expects \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(input_spec)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m input(s),\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    162\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m but it received \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(inputs)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m input tensors. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    163\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mInputs received: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minputs\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    164\u001B[39m     )\n\u001B[32m    165\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m input_index, (x, spec) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(inputs, input_spec)):\n\u001B[32m    166\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m spec \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mValueError\u001B[39m: Layer \"functional_7\" expects 3 input(s), but it received 4 input tensors. Inputs received: [<tf.Tensor 'data:0' shape=(32, 100, 8) dtype=bool>, <tf.Tensor 'data_1:0' shape=(32, 3, 8) dtype=bool>, <tf.Tensor 'data_2:0' shape=(32, 4) dtype=bool>, <tf.Tensor 'data_3:0' shape=(32,) dtype=int32>]"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1fdf6547fe77716c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c96ac4605b6e2b20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# x1 = Input(shape=(None, dim_syndr), name=\"x1_full\")\n",
    "# x2 = Input(shape=(n_steps_net2, dim_syndr), name=\"x2_recent\")\n",
    "# fx = Input(shape=(dim_fsyndr,), name=\"final_increment\")\n",
    "# #\n",
    "# l1_input = Input(shape=(), dtype=tf.int32, name=\"seq_len\")\n",
    "#\n",
    "#\n",
    "#\n",
    "# def make_mask(inputs):\n",
    "#     x1, lengths = inputs\n",
    "#     return tf.sequence_mask(lengths, maxlen=tf.shape(x1)[1])\n",
    "#\n",
    "# mask = layers.Lambda(make_mask, name=\"seq_mask\")([x1, l1_input])\n",
    "#\n",
    "# dropout_rate = 0.2\n",
    "# layer_depth = 64\n",
    "#\n",
    "# # mask_layer = layers.Lambda(lambda x: tf.sequence_mask(x[1], maxlen=tf.shape(x[0])[1]), output_shape=(None,))([x1, l1_input])\n",
    "#\n",
    "#\n",
    "# # Network 1 (full syndrome history)\n",
    "# h1 = layers.LSTM(layer_depth, activation=\"tanh\", return_sequences=True, kernel_regularizer=keras.regularizers.l2(1e-5))(x1, mask=mask)\n",
    "# h1 = layers.Dropout(dropout_rate)(h1)\n",
    "# h1 = layers.LSTM(layer_depth, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(1e-5))(h1)\n",
    "# h1 = layers.Dropout(dropout_rate)(h1)\n",
    "#\n",
    "# p1 = layers.Dense(layer_depth, activation=\"relu\", name=\"p1\", kernel_regularizer=keras.regularizers.l2(1e-5))(h1)\n",
    "# p1 = layers.Dropout(dropout_rate)(p1)\n",
    "# p1 = layers.Dense(1, activation=\"sigmoid\", kernel_regularizer=keras.regularizers.l2(1e-5), name=\"p1_prob\")(p1)\n",
    "#\n",
    "#\n",
    "#\n",
    "# # Network 2 (recent syndrome + final increment)\n",
    "# h2 = layers.LSTM(layer_depth, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(1e-5), return_sequences=True)(x2)\n",
    "# h2 = layers.Dropout(dropout_rate)(h2)\n",
    "# h2 = layers.LSTM(layer_depth, activation=\"tanh\", kernel_regularizer=keras.regularizers.l2(1e-5))(h2)\n",
    "# h2 = layers.Dropout(dropout_rate)(h2)\n",
    "#\n",
    "# p2 = layers.Concatenate()([h2, fx])\n",
    "# p2 = layers.Dense(layer_depth, activation=\"relu\", name=\"p2\", kernel_regularizer=keras.regularizers.l2(1e-5))(p2)\n",
    "# p2 = layers.Dropout(dropout_rate)(p2)\n",
    "# p2 = layers.Dense(1, activation=\"sigmoid\", name=\"p2_prob\", kernel_regularizer=keras.regularizers.l2(1e-5))(p2)\n",
    "#\n",
    "#\n",
    "#\n",
    "# # Final combination p = probabilistic sum\n",
    "# p_final = p1 * (1 - p2) + p2 * (1 - p1)\n",
    "#  # XOR Gate\n",
    "#\n",
    "# model = Model(inputs=[x1, x2, fx, l1_input], outputs=p_final)\n",
    "# model.summary()\n",
    "#\n",
    "# model.compile(\n",
    "#     loss=\"binary_crossentropy\",\n",
    "#     optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "#     metrics=[\"accuracy\"]\n",
    "# )\n",
    "#\n",
    "#\n",
    "# num_epochs = 1000\n",
    "#\n",
    "# checkpoint = ModelCheckpoint(\n",
    "#     'best_model.keras',        # file path to save the model\n",
    "#     monitor='val_accuracy',    # metric to monitor\n",
    "#     verbose=1,                 # prints message when saving\n",
    "#     save_best_only=True,       # only save if improved\n",
    "#     mode='max'                 # 'min' for loss, 'max' for accuracy\n",
    "# )\n",
    "#\n",
    "# early_stop = EarlyStopping(\n",
    "#     monitor='val_accuracy',    # use validation accuracy to monitor\n",
    "#     patience=50,               # stop after n epochs with no improvement\n",
    "#     min_delta=1e-4,            # threshold for minimum change over epochs -> \"no improvement\"\n",
    "#     restore_best_weights=True, # keeps weights from the best epoch\n",
    "#     verbose=1\n",
    "# )\n",
    "#\n",
    "#\n",
    "# results = model.fit(\n",
    "#     train_seq,\n",
    "#     steps_per_epoch=n_batches_train,\n",
    "#     epochs=num_epochs,\n",
    "#     verbose=1,\n",
    "#     validation_data=val_seq,\n",
    "#     validation_steps=n_batches_validation,\n",
    "#     callbacks=[checkpoint]\n",
    "# )"
   ],
   "id": "b5670b2fced8a809"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
